---
title: "Course project: Weight Lifting Accuracy Prediction"
author: "sivarome"
date: "Saturday, September 26, 2015"
output: html_document
---

## Introduction  

### About this Analysis  

This analysis is performed as a part of Coursera assignment. The purpose of the analysis is to predict the accuracy of the weight lifting exercise performed by test subjects using their activity data generated by the wearable devices. Machine learning techniques are applied to predict the accuracy.  

Following dataset is used to train and test the model:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  

Below data set will be used to predict values using the final model:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv  

### About the source data  

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. In this project, the goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants performing barbell lifts, and predict the accuracy of the exercise by classifying the activity into 5 different ways (A, B, C, D ,E). "A" represents correct way, and others represents incorrect ways.  
More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). Citation is added at the end of the report.  

#### Environment  

For this analysis R programming language is used on Windows PC. This report is generated using the knitr package in RStudio.  

 - OS: Windows 8.1 64-bit  
 - R version: 3.1.3  
 - RStudio version: 0.98.1103  

Following packages are used during this analysis. They are pre installed using **install.packages()** function and are loaded using below **library()** functions.

```{r load libraries, message=FALSE, warning=FALSE}
library(ggplot2)
library(caret)
library(rattle)
library(rpart)
library(randomForest)
```

For reproducibility the random seed is set to "007"  

```{r seed, message=FALSE, warning=FALSE}
set.seed(007)
```


## Analysis  

### Loading the data  

Source data set is downloaded from the Source, and is loaded into data frame.  

```{r getting data, cache=TRUE}
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

if (!file.exists("pml-training.csv"))
  {
  download.file(trainingDataURL, "pml-training.csv")
  }

trainingRawDataSet <- read.csv ("pml-training.csv")

dim(trainingRawDataSet)

```

### Cleaning the data  

There are several variables live stddev_, var_, avg_, min_, max_ etc. For this analysis, we focus only on the variables that define the positioning of the sensors (like x, y z coordinates). Also, we need the roll, pitch and yaw variables that gives the angular displacement of the devices. We consider user_name and classe as the mandatory variables.  

In following section we select only the above mentioned columns using a filter based on regular expression on column names.  

```{r cleaning data}
colnames_regx <- "(^roll|^pitch|^yaw|classe|user_name|.*_x$|.*_y$|.*_z$).*"
select_cols <- grep(colnames_regx, names(trainingRawDataSet), perl=TRUE, value=TRUE)

trainingDataSet <- subset(trainingRawDataSet, select = select_cols)
```

Here is the final list of columns.  
```{r new data}
names(trainingDataSet)
```


### Exploratory analysis  

Lets have a look at how the forearm data is related with user and the classe variables. Here is a pairs plot with selected columns.  

```{r exploratory analysis forearm}

select_cols <- paste0("(?:^roll|^pitch|^yaw)_forearm", "|user_name|classe")

plotData <-trainingDataSet[,grep(select_cols, names(trainingDataSet), perl=TRUE)]
featurePlot(x=plotData, y=plotData$classe, plot="pairs")

```

Similarly we can see how the belt data is related with user and the classe variables. Here is a pairs plot with selected columns.  

```{r exploratory analysis belt}

select_cols <- paste0("(?:^roll|^pitch|^yaw)_belt", "|user_name|classe")

plotData <-trainingDataSet[,grep(select_cols, names(trainingDataSet), perl=TRUE)]
featurePlot(x=plotData, y=plotData$classe, plot="pairs")

```

These plots indicate that almost all users performed the exercise with changing levels of accuracy.  

### Prediction model  

In this analysis, two algorithms are tested, **rpart** (Decision Tree) and **rf** (Random Forest).  The most accurate model will be selected based on the results of these tests.  

First the source data set will be divided into 2 partitions. 60 percent of the data will be used to train the model, and the other 40 percent will be used to test the model.  

```{r create partitions, message=FALSE}

inTrain <- createDataPartition(y = trainingDataSet$classe, p=0.6, list=FALSE)

trainData <- trainingDataSet[inTrain,]
testData <- trainingDataSet[-inTrain,]

```

#### rpart Algorithm  

First we apply Decision Tree algorithm to fit the model using the training data set.  

```{r rpart algorithm}

rpartFit <- train(classe ~ ., data=trainData, method="rpart",
                  preProcess=c("center", "scale"), 
                  trControl=trainControl(method="cv", number=5))

fancyRpartPlot(rpartFit$finalModel)
```

We use this model to predict the test data set and compare the actual values using the confusion matrix.  

```{r predict rpart}
rpart_predictions <- predict(rpartFit, newdata=testData)
rpart_cMatrix <- confusionMatrix(rpart_predictions, testData$classe)
print(rpart_cMatrix)
```

This model gives an accuracy of `r rpart_cMatrix$overall[1]`. This is too low and  is not what we expect when we apply a prediction model.  

#### Random Forest Algorithm (rf)  

Next model is based on Random Forest algrithm. This algorithm usually takes long time, so we use train control methos as "none" to speedup the process. Also, we use tuneGrid option to increase the performance. In this analysis, mtry value is set to 3.  

Below code applies Random Forest algorithm to fit the model using the training data set.  

```{r rf algorithm, cache=TRUE}

fitControl <- trainControl(method = "none")
tgrid <- expand.grid(mtry=c(3)) 
rfFit <- train (classe ~ ., data = trainData, method = "rf", 
                trControl = fitControl, 
                tuneGrid = tgrid)
```

We use this model to predict the test data set and compare the actual values using the confusion matrix.  

```{r predict random forest}
rf_predictions <- predict(rfFit, newdata=testData)
rf_cMatrix <- confusionMatrix(rf_predictions, testData$classe)
print(rf_cMatrix)

```

This model gives an accuracy of `r rf_cMatrix$overall[1]`. This looks impressive.  

### Out of Sample Error  

Out of Sample Error is the error rate we get when we apply a predicted model on the test data set. It is calculated using the formula:  
**Out of Sample Error = 1 - Accuracy**  

In this analysis 2 models are tested. Following are the Out of Sample Error rates for both the models.  
 * rpart (Decision Tree): `r 1 - rpart_cMatrix$overall[1]`  
 * rf (Random Forest):  `r 1 - rf_cMatrix$overall[1]`  
 
We can see that the Random Forest algorithm gives very impressive model compared to Decision Tree model. Hence we will use the Random Forest model as the final model.  


### Citation  

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Read more : http://groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz3mrhFyHib  


### Assignment validation

```{r assignment data, cache=TRUE}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if (!file.exists("pml-testing.csv"))
  {
  download.file(testDataURL, "pml-testing.csv")
  }

testDataSet <- read.csv ("pml-testing.csv")
```

Predicted values for the test data set given in the source data.
```{r assignment submission}
predictedValues <- predict(rfFit, newdata=testDataSet)
print(predictedValues)
```

```{r submission, echo=FALSE, eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```